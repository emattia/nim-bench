{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib seaborn numpy pandas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_requests</th>\n",
       "      <th>total_time</th>\n",
       "      <th>concurrent_requests</th>\n",
       "      <th>n_requests_per_thread</th>\n",
       "      <th>max_tokens_per_request</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374023</td>\n",
       "      <td>9975</td>\n",
       "      <td>100</td>\n",
       "      <td>180.026637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>383998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1655656</td>\n",
       "      <td>49890</td>\n",
       "      <td>500</td>\n",
       "      <td>307.801830</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1705546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3397635</td>\n",
       "      <td>99786</td>\n",
       "      <td>1000</td>\n",
       "      <td>474.586808</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3497421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6695148</td>\n",
       "      <td>199752</td>\n",
       "      <td>2000</td>\n",
       "      <td>843.704915</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>320467</td>\n",
       "      <td>23462</td>\n",
       "      <td>100</td>\n",
       "      <td>384.522558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>343929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600568</td>\n",
       "      <td>119496</td>\n",
       "      <td>500</td>\n",
       "      <td>605.821418</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1720064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3323799</td>\n",
       "      <td>243747</td>\n",
       "      <td>1000</td>\n",
       "      <td>840.312524</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3567546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6619255</td>\n",
       "      <td>491796</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.139220</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7111051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>287814</td>\n",
       "      <td>30752</td>\n",
       "      <td>100</td>\n",
       "      <td>494.043173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>318566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1707211</td>\n",
       "      <td>151332</td>\n",
       "      <td>500</td>\n",
       "      <td>737.878834</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1858543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3334935</td>\n",
       "      <td>308587</td>\n",
       "      <td>1000</td>\n",
       "      <td>1040.482235</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3643522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6849572</td>\n",
       "      <td>607265</td>\n",
       "      <td>2000</td>\n",
       "      <td>1727.446096</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>7456837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_tokens  completion_tokens  total_requests   total_time  \\\n",
       "2          374023               9975             100   180.026637   \n",
       "3         1655656              49890             500   307.801830   \n",
       "4         3397635              99786            1000   474.586808   \n",
       "5         6695148             199752            2000   843.704915   \n",
       "6          320467              23462             100   384.522558   \n",
       "7         1600568             119496             500   605.821418   \n",
       "8         3323799             243747            1000   840.312524   \n",
       "9         6619255             491796            2000  1415.139220   \n",
       "10         287814              30752             100   494.043173   \n",
       "11        1707211             151332             500   737.878834   \n",
       "12        3334935             308587            1000  1040.482235   \n",
       "13        6849572             607265            2000  1727.446096   \n",
       "\n",
       "    concurrent_requests  n_requests_per_thread  max_tokens_per_request  \\\n",
       "2                   1.0                  100.0                   100.0   \n",
       "3                   5.0                  100.0                   100.0   \n",
       "4                  10.0                  100.0                   100.0   \n",
       "5                  20.0                  100.0                   100.0   \n",
       "6                   1.0                  100.0                   500.0   \n",
       "7                   5.0                  100.0                   500.0   \n",
       "8                  10.0                  100.0                   500.0   \n",
       "9                  20.0                  100.0                   500.0   \n",
       "10                  1.0                  100.0                  1000.0   \n",
       "11                  5.0                  100.0                  1000.0   \n",
       "12                 10.0                  100.0                  1000.0   \n",
       "13                 20.0                  100.0                  1000.0   \n",
       "\n",
       "    total_tokens  \n",
       "2         383998  \n",
       "3        1705546  \n",
       "4        3497421  \n",
       "5        6894900  \n",
       "6         343929  \n",
       "7        1720064  \n",
       "8        3567546  \n",
       "9        7111051  \n",
       "10        318566  \n",
       "11       1858543  \n",
       "12       3643522  \n",
       "13       7456837  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, to_rgba\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "BASE_COLOR = \"#FAF7F4\"\n",
    "BASE_ALPHA = 0.05\n",
    "sns.set(rc={'axes.facecolor':BASE_COLOR, 'figure.facecolor':BASE_COLOR})\n",
    "\n",
    "df=pd.read_csv('../old-data/llm-summarization-token-throughput/results_NVIDIA A100-SXM4-40GB_2024-06-05_10:23:13.csv')\n",
    "df = df[df.prompt_tokens>45589] # some tiny experiments in the raw data.\n",
    "df['total_tokens'] = df.prompt_tokens + df.completion_tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " result = subprocess.run(\n",
    "    ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    check=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Split the output into lines (one line per GPU)\n",
    "gpu_names = result.stdout.strip().split('\\n')\n",
    "\n",
    "if len(gpu_names) > 1:\n",
    "    device = gpu_names[0]\n",
    "    print('Found multiple device types. Set to %, manually change it if you ran the experiment on a different device.' % device)\n",
    "else:\n",
    "    device = gpu_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_requests</th>\n",
       "      <th>total_time</th>\n",
       "      <th>concurrent_requests</th>\n",
       "      <th>n_requests_per_thread</th>\n",
       "      <th>max_tokens_per_request</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.013840e+06</td>\n",
       "      <td>194653.333333</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>754.313854</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>533.333333</td>\n",
       "      <td>3.208494e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.501159e+06</td>\n",
       "      <td>191101.358042</td>\n",
       "      <td>742.232505</td>\n",
       "      <td>458.771874</td>\n",
       "      <td>7.422325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384.550111</td>\n",
       "      <td>2.664607e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.878140e+05</td>\n",
       "      <td>9975.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>180.026637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.185660e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.293932e+06</td>\n",
       "      <td>45105.500000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>452.070746</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.375159e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.515505e+06</td>\n",
       "      <td>135414.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>671.850126</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2.677982e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.203040e+06</td>\n",
       "      <td>259957.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>892.899245</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.456366e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.849572e+06</td>\n",
       "      <td>607265.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1727.446096</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>7.456837e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_tokens  completion_tokens  total_requests   total_time  \\\n",
       "count   1.200000e+01          12.000000       12.000000    12.000000   \n",
       "mean    3.013840e+06      194653.333333      900.000000   754.313854   \n",
       "std     2.501159e+06      191101.358042      742.232505   458.771874   \n",
       "min     2.878140e+05        9975.000000      100.000000   180.026637   \n",
       "25%     1.293932e+06       45105.500000      400.000000   452.070746   \n",
       "50%     2.515505e+06      135414.000000      750.000000   671.850126   \n",
       "75%     4.203040e+06      259957.000000     1250.000000   892.899245   \n",
       "max     6.849572e+06      607265.000000     2000.000000  1727.446096   \n",
       "\n",
       "       concurrent_requests  n_requests_per_thread  max_tokens_per_request  \\\n",
       "count            12.000000                   12.0               12.000000   \n",
       "mean              9.000000                  100.0              533.333333   \n",
       "std               7.422325                    0.0              384.550111   \n",
       "min               1.000000                  100.0              100.000000   \n",
       "25%               4.000000                  100.0              100.000000   \n",
       "50%               7.500000                  100.0              500.000000   \n",
       "75%              12.500000                  100.0             1000.000000   \n",
       "max              20.000000                  100.0             1000.000000   \n",
       "\n",
       "       total_tokens  \n",
       "count  1.200000e+01  \n",
       "mean   3.208494e+06  \n",
       "std    2.664607e+06  \n",
       "min    3.185660e+05  \n",
       "25%    1.375159e+06  \n",
       "50%    2.677982e+06  \n",
       "75%    4.456366e+06  \n",
       "max    7.456837e+06  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any', inplace=True)\n",
    "p_tokens, c_tokens = df.prompt_tokens.sum(), df.completion_tokens.sum()\n",
    "total_gpu_time = str(datetime.timedelta(seconds=df.total_time.sum()))\n",
    "title = f\"{p_tokens:,} prompt tokens, {c_tokens:,} completion tokens, in {total_gpu_time} on {device}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (4061265015.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"(Estimated) number of document pages processed is {\u001b[0m\n\u001b[0m                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "words_per_token = 0.75\n",
    "words_in_a_page = 500\n",
    "seconds_per_hour = 3600\n",
    "\n",
    "print(f\"(Estimated) number of document pages processed is {\n",
    "    round(p_tokens * words_per_token * (1 / words_in_a_page))\n",
    "}.\")\n",
    "\n",
    "print(f\"(Estimated) number of summary pages generated is {\n",
    "    round(c_tokens * words_per_token * (1 / words_in_a_page))\n",
    "}.\")\n",
    "print(f\"Billable compute time is {round(df.total_time.sum() / 3600, 3)} {device} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2588316424.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    if x < a or x > b:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "REQUEST_COLOR = \"#8E6A1A\"\n",
    "CONCURRENCY_COLOR = \"#37795D\"\n",
    "BG_COLOR = \"#F5EFF9\"\n",
    "\n",
    "custom_params = {\n",
    "    \"axes.spines.left\": False, \n",
    "    \"axes.spines.right\": False, \n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.bottom\": False,\n",
    "    \"axes.grid\": False,\n",
    "    \"axes.facecolor\": BG_COLOR,\n",
    "    \"figure.facecolor\": BG_COLOR\n",
    "}\n",
    "sns.set_theme(rc=custom_params)\n",
    "\n",
    "fig, ax = plt.subplot_mosaic(mosaic=[\n",
    "    [ 'time and tokens - prompt' ],\n",
    "    [ 'time and tokens - completion'] \n",
    "], figsize=(10,8))\n",
    "\n",
    "def create_mapping_function(a, b, _max = 250, _min = 10):\n",
    "    def mapping_function(x):\n",
    "        if x < a or x > b:\n",
    "            raise ValueError(f\"The input number {x} is out of the range [{a}, {b}]\")\n",
    "        return _min + (x - a) * (_max - _min) / (b - a)\n",
    "    return mapping_function\n",
    "\n",
    "def create_alpha_colormap(hex_color, alpha_bottom, alpha_top):\n",
    "    rgb_color = to_rgba(hex_color)[:3] \n",
    "    return LinearSegmentedColormap.from_list(\n",
    "        'alpha_colormap',\n",
    "        [(rgb_color[0], rgb_color[1], rgb_color[2], alpha_bottom),\n",
    "         (rgb_color[0], rgb_color[1], rgb_color[2], alpha_top)]\n",
    "    )\n",
    "\n",
    "alpha_bottom = .2\n",
    "alpha_top = 1.\n",
    "max_token_alpha_map = create_mapping_function(\n",
    "    df.max_tokens_per_request.min(), df.max_tokens_per_request.max(), \n",
    "    _max = alpha_top, _min = alpha_bottom\n",
    ")\n",
    "max_tokens_alphas = [max_token_alpha_map(v) for v in df.max_tokens_per_request]\n",
    "request_map_for_colorbar = create_alpha_colormap(REQUEST_COLOR, alpha_bottom, alpha_top)\n",
    "\n",
    "max_prompt_tokens = df.prompt_tokens.max()\n",
    "min_prompt_tokens = df.prompt_tokens.min()\n",
    "prompt_map = create_mapping_function(a=min_prompt_tokens, b=max_prompt_tokens)\n",
    "prompt_tokens_size_scaling = [prompt_map(p_tokens) for p_tokens in df.prompt_tokens]\n",
    "prompt_tokens_size_scaling_labels = [\n",
    "    f\"{p:,}\"\n",
    "    for p in [min_prompt_tokens, max_prompt_tokens]\n",
    "]\n",
    "\n",
    "max_completion_tokens = df.completion_tokens.max()\n",
    "min_completion_tokens = df.completion_tokens.min()\n",
    "completions_map = create_mapping_function(a=min_completion_tokens, b=max_completion_tokens)\n",
    "completion_tokens_size_scaling = [completions_map(c_tokens) for c_tokens in df.completion_tokens]\n",
    "completion_tokens_size_scaling_labels = [\n",
    "    f\"{c:,}\"\n",
    "    for c in [min_completion_tokens, max_completion_tokens]\n",
    "]\n",
    "\n",
    "request_ticks = df.total_requests.unique()\n",
    "specific_request_tick_labels = [str(int(tick)) for tick in request_ticks]\n",
    "specific_concurrency_ticks = df.concurrent_requests.unique()\n",
    "specific_concurrency_tick_labels = [str(int(tick)) for tick in specific_concurrency_ticks]\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=request_map_for_colorbar, norm=plt.Normalize(vmin=alpha_bottom, vmax=alpha_top))\n",
    "sm.set_array([])\n",
    "\n",
    "def color_ax(handle='time and tokens - prompt', is_prompt=True, is_bottom=False):\n",
    "\n",
    "    # Cbar only if bottom\n",
    "    if is_bottom:\n",
    "        ax[handle].set_xlabel(f'Total GPU time (s) in batch', labelpad=LABELPAD)\n",
    "    else:\n",
    "        ax[handle].set_title(title, y=1.3)\n",
    "        ax[handle].set_xticks([])\n",
    "        divider = make_axes_locatable(ax[handle])\n",
    "        x_start = df.total_time.min()\n",
    "        x_dist = df.total_time.max() - df.total_time.min()\n",
    "        factor = request_ticks.max() * .35\n",
    "        y_start = request_ticks.max() + factor\n",
    "        y_dist = factor // 7\n",
    "    \n",
    "        cax = ax[handle].inset_axes([x_start, y_start, x_dist, y_dist], transform=ax[handle].transData)\n",
    "        cbar = fig.colorbar(sm, orientation='horizontal', cax=cax)\n",
    "        cbar.set_ticks(max_tokens_alphas)\n",
    "        cbar.set_ticklabels([str(int(max_tpr)) for max_tpr in df.max_tokens_per_request], color=REQUEST_COLOR)\n",
    "        cbar.set_label('Max tokens per request', color=REQUEST_COLOR)\n",
    "        \n",
    "    # ax[handle].yaxis.label.set_color(REQUEST_COLOR)\n",
    "    ax[handle].tick_params(axis='y', colors=REQUEST_COLOR)\n",
    "    ax[handle].set_ylabel('Total requests in batch', labelpad=LABELPAD)\n",
    "    ax[handle].set_yticks(request_ticks)\n",
    "    ax[handle].set_yticklabels(specific_request_tick_labels)\n",
    "\n",
    "    ax_time_tokens_twin = ax[handle].twinx()\n",
    "    ax_time_tokens_twin.set_ylabel('Number of threads')\n",
    "    # ax_time_tokens_twin.yaxis.label.set_color(CONCURRENCY_COLOR)\n",
    "    ax_time_tokens_twin.tick_params(axis='y', colors=CONCURRENCY_COLOR)\n",
    "    ax_time_tokens_twin.set_yticks(specific_concurrency_ticks)\n",
    "    ax_time_tokens_twin.set_yticklabels(specific_concurrency_tick_labels, color=CONCURRENCY_COLOR)\n",
    "\n",
    "    if is_prompt:\n",
    "        for t, r, a, s in zip(\n",
    "            df.total_time, df.total_requests, max_tokens_alphas, prompt_tokens_size_scaling\n",
    "        ):\n",
    "            ax[handle].scatter(\n",
    "                t, \n",
    "                r, \n",
    "                marker='o',\n",
    "                color = REQUEST_COLOR, \n",
    "                s = s,\n",
    "                alpha = a\n",
    "            )\n",
    "    else:\n",
    "        for t, r, a, s in zip(\n",
    "            df.total_time, df.total_requests, max_tokens_alphas, completion_tokens_size_scaling\n",
    "        ):\n",
    "            ax[handle].scatter(\n",
    "                t, \n",
    "                r, \n",
    "                marker='s',\n",
    "                color = REQUEST_COLOR, \n",
    "                s = s,\n",
    "                alpha = a\n",
    "            )\n",
    "        \n",
    "    \n",
    "    for val in df.max_tokens_per_request.unique():\n",
    "        _df = df[df.max_tokens_per_request == val]\n",
    "        a = max_token_alpha_map(val)\n",
    "        slope, intercept = np.polyfit(_df.total_time, _df.total_requests, deg=1)\n",
    "        _y = _df.total_time * slope + intercept\n",
    "        ax[handle].plot(\n",
    "            _df.total_time, \n",
    "            _y, \n",
    "            alpha = a, \n",
    "            color = REQUEST_COLOR,\n",
    "        )\n",
    "        x_pos = _df.total_time.values[-1]\n",
    "        x_pos -= 0.05 * request_ticks.max()\n",
    "        y_pos = _y.values[-1]\n",
    "        y_pos *= 1.05\n",
    "        ax[handle].text(x_pos, y_pos, f\"Slope = {round(slope, 1)}\", fontsize=12, color=REQUEST_COLOR, alpha=a)\n",
    "\n",
    "    if is_prompt:\n",
    "        handles = [\n",
    "            ax[handle].scatter([], [], s=prompt_map(min_prompt_tokens), color=REQUEST_COLOR, marker='o'),\n",
    "            ax[handle].scatter([], [], s=prompt_map(max_prompt_tokens), color=REQUEST_COLOR, marker='o')\n",
    "        ]\n",
    "        leg = ax[handle].legend(\n",
    "            handles, \n",
    "            prompt_tokens_size_scaling_labels, \n",
    "            title=\"Prompt tokens in batch\",\n",
    "            bbox_to_anchor=(.25, 0.9),\n",
    "            borderpad=0.8\n",
    "        )\n",
    "    else:\n",
    "        handles = [\n",
    "            ax[handle].scatter([], [], s=completions_map(min_completion_tokens), color=REQUEST_COLOR, marker='s'),\n",
    "            ax[handle].scatter([], [], s=completions_map(max_completion_tokens), color=REQUEST_COLOR, marker='s')\n",
    "        ]\n",
    "        leg = ax[handle].legend(\n",
    "            handles, \n",
    "            completion_tokens_size_scaling_labels, \n",
    "            title=\"Completion tokens in batch\",\n",
    "            bbox_to_anchor=(.25, 0.9),\n",
    "            borderpad=0.8\n",
    "        )\n",
    "    \n",
    "    leg._legend_box.align = \"left\"\n",
    "    \n",
    "    _10pct = request_ticks.max() * .1\n",
    "    ax[handle].set_ylim([request_ticks.min() - _10pct, request_ticks.max() + _10pct])\n",
    "    \n",
    "    for val in specific_concurrency_ticks:\n",
    "        ax_time_tokens_twin.axhline(y=val, alpha=0.1, color=CONCURRENCY_COLOR)\n",
    "    \n",
    "    _10pct = specific_concurrency_ticks.max() * .1\n",
    "    ax_time_tokens_twin.set_ylim(\n",
    "        [specific_concurrency_ticks.min() - _10pct, specific_concurrency_ticks.max() + _10pct]\n",
    "    )\n",
    "\n",
    "\n",
    "color_ax(handle='time and tokens - prompt', is_prompt=True, is_bottom=False)\n",
    "color_ax(handle='time and tokens - completion', is_prompt=False, is_bottom=True)\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "* More tokens per request --> More "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "fig.savefig(f'results_{device}_{now}.png')\n",
    "fig.savefig(f'results_{device}_{now}_transparent.png', transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
